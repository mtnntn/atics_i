{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from projects.first_project.NetworkModel import NetworkModel\n",
    "\n",
    "path_to_claims = os.path.join(\"datasets\", \"population\", \"Population_claims.csv\")\n",
    "path_to_groundtruth = os.path.join(\"datasets\", \"population\", \"Population_groundtruth.csv\")\n",
    "results = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading claims ...\nLoading ground truth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of claims : 318\nNumber of sources: 231\nBuilding sensing matrix ...\nSources processed: 0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sources processed: 200 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n"
     ]
    }
   ],
   "source": [
    "# Generate sensing matrix\n",
    "\n",
    "nm = NetworkModel(path_to_claims, path_to_groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test the model with 231 neurons in the second layer and 207 in the third one\nSplitting in test set and train set...\nCompiling model ...\nTrain Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model ... \n"
     ]
    }
   ],
   "source": [
    "shl_neurons = int(nm.num_of_sources)    # 100%\n",
    "thl_neurons = shl_neurons\n",
    "\n",
    "\n",
    "print(\"Train and Test the model with %i neurons in the second layer and %i in the third one\" % (shl_neurons, thl_neurons))\n",
    "nm.train_and_test_model(shl_units=shl_neurons, thl_units=thl_neurons)\n",
    "new_test = str(shl_neurons) + \" - \" + str(thl_neurons)\n",
    "results[new_test] = nm.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test the model with 231 neurons in the second layer and 207 in the third one\nSplitting in test set and train set...\nCompiling model ...\nTrain Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model ... \n"
     ]
    }
   ],
   "source": [
    "shl_neurons = int(nm.num_of_sources/2)  # 50%\n",
    "thl_neurons = shl_neurons\n",
    "\n",
    "print(\"Train and Test the model with %i neurons in the second layer and %i in the third one\" % (shl_neurons, thl_neurons))\n",
    "nm.train_and_test_model(shl_units=shl_neurons, thl_units=thl_neurons)\n",
    "\n",
    "results[str(shl_neurons) + \" - \" + str(thl_neurons)] = nm.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test the model with 231 neurons in the second layer and 207 in the third one\nSplitting in test set and train set...\nCompiling model ...\nTrain Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model ... \n"
     ]
    }
   ],
   "source": [
    "shl_neurons = int(nm.num_of_sources - nm.num_of_sources*0.3)    # 70%\n",
    "thl_neurons = shl_neurons\n",
    "\n",
    "print(\"Train and Test the model with %i neurons in the second layer and %i in the third one\" % (shl_neurons, thl_neurons))\n",
    "nm.train_and_test_model(shl_units=shl_neurons, thl_units=thl_neurons)\n",
    "\n",
    "results[str(shl_neurons) + \" - \" + str(thl_neurons)] = nm.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test the model with 231 neurons in the second layer and 207 in the third one\nSplitting in test set and train set...\nCompiling model ...\nTrain Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model ... \n"
     ]
    }
   ],
   "source": [
    "shl_neurons = int(nm.num_of_sources - nm.num_of_sources*0.1)    # 90%\n",
    "thl_neurons = shl_neurons\n",
    "\n",
    "print(\"Train and Test the model with %i neurons in the second layer and %i in the third one\" % (shl_neurons, thl_neurons))\n",
    "nm.train_and_test_model(shl_units=shl_neurons, thl_units=thl_neurons)\n",
    "\n",
    "results[str(shl_neurons) + \" - \" + str(thl_neurons)] = nm.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test the model with 231 neurons in the second layer and 207 in the third one\nSplitting in test set and train set...\nCompiling model ...\nTrain Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model ... \n"
     ]
    }
   ],
   "source": [
    "shl_neurons = int(nm.num_of_sources)    # 100%\n",
    "thl_neurons = int(shl_neurons/2)    # 50%\n",
    "\n",
    "print(\"Train and Test the model with %i neurons in the second layer and %i in the third one\" % (shl_neurons, thl_neurons))\n",
    "nm.train_and_test_model(shl_units=shl_neurons, thl_units=thl_neurons)\n",
    "\n",
    "results[str(shl_neurons) + \" - \" + str(thl_neurons)] = nm.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test the model with 231 neurons in the second layer and 207 in the third one\nSplitting in test set and train set...\nCompiling model ...\nTrain Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model ... \n"
     ]
    }
   ],
   "source": [
    "shl_neurons = nm.num_of_sources  # 100%\n",
    "thl_neurons = int(shl_neurons - shl_neurons*0.3)    # 70 %\n",
    "\n",
    "print(\"Train and Test the model with %i neurons in the second layer and %i in the third one\" % (shl_neurons, thl_neurons))\n",
    "nm.train_and_test_model(shl_units=shl_neurons, thl_units=thl_neurons)\n",
    "\n",
    "results[str(shl_neurons) + \" - \" + str(thl_neurons)] = nm.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test the model with 231 neurons in the second layer and 207 in the third one\nSplitting in test set and train set...\nCompiling model ...\nTrain Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model ... \n"
     ]
    }
   ],
   "source": [
    "shl_neurons = nm.num_of_sources  # 100%\n",
    "thl_neurons = int(shl_neurons - shl_neurons*0.1)    # 90 %\n",
    "\n",
    "print(\"Train and Test the model with %i neurons in the second layer and %i in the third one\" % (shl_neurons, thl_neurons))\n",
    "nm.train_and_test_model(shl_units=shl_neurons, thl_units=thl_neurons)\n",
    "\n",
    "results[str(shl_neurons) + \" - \" + str(thl_neurons)] = nm.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test the model with 161 neurons in the second layer and 115 in the third one\nSplitting in test set and train set...\nCompiling model ...\nTrain Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model ... \n"
     ]
    }
   ],
   "source": [
    "shl_neurons = int(nm.num_of_sources - nm.num_of_sources*0.1)  # 90%\n",
    "thl_neurons = int(nm.num_of_sources - nm.num_of_sources*0.3)    # 70 %\n",
    "\n",
    "print(\"Train and Test the model with %i neurons in the second layer and %i in the third one\" % (shl_neurons, thl_neurons))\n",
    "nm.train_and_test_model(shl_units=shl_neurons, thl_units=thl_neurons)\n",
    "\n",
    "results[str(shl_neurons) + \" - \" + str(thl_neurons)] = nm.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test the model with 161 neurons in the second layer and 115 in the third one\nSplitting in test set and train set...\nCompiling model ...\nTrain Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model ... \n"
     ]
    }
   ],
   "source": [
    "shl_neurons = int(nm.num_of_sources - nm.num_of_sources*0.1)  # 90%\n",
    "thl_neurons = int(nm.num_of_sources/2)    # 50 %\n",
    "\n",
    "print(\"Train and Test the model with %i neurons in the second layer and %i in the third one\" % (shl_neurons, thl_neurons))\n",
    "nm.train_and_test_model(shl_units=shl_neurons, thl_units=thl_neurons)\n",
    "\n",
    "results[str(shl_neurons) + \" - \" + str(thl_neurons)] = nm.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test the model with 161 neurons in the second layer and 115 in the third one\nSplitting in test set and train set...\nCompiling model ...\nTrain Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model ... \n"
     ]
    }
   ],
   "source": [
    "shl_neurons = int(nm.num_of_sources - nm.num_of_sources*0.3)  # 70%\n",
    "thl_neurons = int(nm.num_of_sources/2)    # 50 %\n",
    "\n",
    "print(\"Train and Test the model with %i neurons in the second layer and %i in the third one\" % (shl_neurons, thl_neurons))\n",
    "nm.train_and_test_model(shl_units=shl_neurons, thl_units=thl_neurons)\n",
    "\n",
    "results[str(shl_neurons) + \" - \" + str(thl_neurons)] = nm.evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231 - 161 \nloss: 7.60% - accuracy: 100.00%\n\n\n207 - 115 \nloss: 9.89% - accuracy: 100.00%\n\n\n207 - 161 \nloss: 7.48% - accuracy: 100.00%\n\n\n231 - 115 \nloss: 9.32% - accuracy: 100.00%\n\n\n161 - 115 \nloss: 9.71% - accuracy: 100.00%\n\n\n161 - 161 \nloss: 9.95% - accuracy: 100.00%\n\n\n207 - 207 \nloss: 7.75% - accuracy: 100.00%\n\n\n115 - 115 \nloss: 10.34% - accuracy: 100.00%\n\n\n231 - 231 \nloss: 9.16% - accuracy: 100.00%\n\n\n231 - 207 \nloss: 9.62% - accuracy: 100.00%\n\n\n"
     ]
    }
   ],
   "source": [
    "# Printing results\n",
    "for el in results:\n",
    "    print(el, results[el])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
