{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from .DatetimeExtractor import *\n",
    "\n",
    "claims_folder = os.path.join(\"..\", \"..\", \"datasets\", \"flights\", \"clean_flight\")\n",
    "groundtruth_folder = os.path.join(\"..\", \"..\",\"datasets\", \"flights\", \"flight_truth\")\n",
    "\n",
    "all_claims_filename = \"clean_flight.csv\"\n",
    "all_truth_filename = \"flight_truth.csv\"\n",
    "\n",
    "all_claims_file = os.path.join(claims_folder, all_claims_filename)\n",
    "all_groundtruth_file = os.path.join(groundtruth_folder, all_truth_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_claims = [\n",
    "    \"source\",\n",
    "    \"flight_number\",\n",
    "    \"scheduled_departure\",\n",
    "    \"actual_departure\",\n",
    "    \"departure_gate\", \n",
    "    \"scheduled_arrival\",\n",
    "    \"actual_arrival\",\n",
    "    \"arrival_gate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_gate(gate):\n",
    "    gate = gate.strip()\n",
    "    gate = gate.upper()\n",
    "    if gate == \"-\" or gate == \"--\" or gate == \"\" or gate == \"?\" or gate == \"$\" or gate == \"NOT PROVIDED BY AIRLINE\" or gate is None:\n",
    "        gate = \"-\"\n",
    "    return gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(all_claims_file):\n",
    "    os.remove(all_claims_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: ../../datasets/flights/clean_flight/2011-12-10-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-29-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-14-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-08-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-27-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-30-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-09-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-11-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-19-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2012-01-02-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-16-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-31-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-02-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-07-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-28-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-03-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-20-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-25-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-15-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-18-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-01-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-04-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-22-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-26-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-12-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2012-01-03-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2012-01-01-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-17-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-24-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-13-data.txt\n",
      "Importing: ../../datasets/flights/clean_flight/2011-12-05-data.txt\n"
     ]
    }
   ],
   "source": [
    "clean_claims = list()\n",
    "\n",
    "# claims input files, ignore any other hidden file in the folder...\n",
    "claims_files = [f for f in os.listdir(claims_folder) if not f.startswith('.')]\n",
    "\n",
    "for file_name in claims_files:\n",
    "    \n",
    "    file_path = os.path.join(claims_folder, file_name)\n",
    "\n",
    "    print(\"Importing: \" + file_path)\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"iso-8859-1\") as f:\n",
    "       \n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        year, month, day, c = file_name.split(\"-\")\n",
    "        dt_ex = DatetimeExtractor(int(year), int(month), int(day))\n",
    "\n",
    "        for i, row in enumerate(reader):\n",
    "            try:\n",
    "                source = row[header_claims.index(\"source\")].strip().upper()\n",
    "                flight = row[header_claims.index(\"flight_number\")].strip().upper()\n",
    "                departure_gate = import_gate(row[header_claims.index(\"departure_gate\")])  # one hot\n",
    "                arrival_gate = import_gate(row[header_claims.index(\"arrival_gate\")])  # one hot\n",
    "                scheduled_departure = dt_ex.get_datetime(row[header_claims.index(\"scheduled_departure\")])\n",
    "                scheduled_arrival = dt_ex.get_datetime(row[header_claims.index(\"scheduled_arrival\")])\n",
    "                actual_departure = dt_ex.get_datetime(row[header_claims.index(\"actual_departure\")])\n",
    "                actual_arrival = dt_ex.get_datetime(row[header_claims.index(\"actual_arrival\")])    \n",
    "            except Exception as p:\n",
    "                print(p)\n",
    "            \n",
    "            record = [source, flight, scheduled_departure, actual_departure, departure_gate, scheduled_arrival, actual_arrival, arrival_gate]\n",
    "            clean_claims.append(record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>scheduled_departure</th>\n",
       "      <th>actual_departure</th>\n",
       "      <th>departure_gate</th>\n",
       "      <th>scheduled_arrival</th>\n",
       "      <th>actual_arrival</th>\n",
       "      <th>arrival_gate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UA</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>2011-12-10 14:05:00</td>\n",
       "      <td>2011-12-10 17:00:00</td>\n",
       "      <td>-</td>\n",
       "      <td>2011-12-10 17:01:00</td>\n",
       "      <td>2011-12-10 19:44:00</td>\n",
       "      <td>E24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIRTRAVELCENTER</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2011-12-10 13:53:00</td>\n",
       "      <td>-</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2011-12-10 18:18:00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MYRATEPLAN</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2011-12-10 13:53:00</td>\n",
       "      <td>-</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2011-12-10 18:18:00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HELLOFLIGHT</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2011-12-10 13:53:00</td>\n",
       "      <td>-</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2011-12-10 18:18:00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FLYTECOMM</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2011-12-10 13:53:00</td>\n",
       "      <td>-</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2011-12-10 18:18:00</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source    flight_number scheduled_departure    actual_departure  \\\n",
       "0               UA  UA-1534-RTB-IAH 2011-12-10 14:05:00 2011-12-10 17:00:00   \n",
       "1  AIRTRAVELCENTER  UA-1534-RTB-IAH                 NaT 2011-12-10 13:53:00   \n",
       "2       MYRATEPLAN  UA-1534-RTB-IAH                 NaT 2011-12-10 13:53:00   \n",
       "3      HELLOFLIGHT  UA-1534-RTB-IAH                 NaT 2011-12-10 13:53:00   \n",
       "4        FLYTECOMM  UA-1534-RTB-IAH                 NaT 2011-12-10 13:53:00   \n",
       "\n",
       "  departure_gate   scheduled_arrival      actual_arrival arrival_gate  \n",
       "0              - 2011-12-10 17:01:00 2011-12-10 19:44:00          E24  \n",
       "1              -                 NaT 2011-12-10 18:18:00            -  \n",
       "2              -                 NaT 2011-12-10 18:18:00            -  \n",
       "3              -                 NaT 2011-12-10 18:18:00            -  \n",
       "4              -                 NaT 2011-12-10 18:18:00            -  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims = pd.DataFrame(clean_claims)\n",
    "claims.columns = header_claims\n",
    "claims.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "claims.to_csv(all_claims_file, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_truth = [\n",
    "    \"flight_number\",\n",
    "    \"scheduled_departure\",\n",
    "    \"actual_departure\",\n",
    "    \"departure_gate\", \n",
    "    \"scheduled_arrival\",\n",
    "    \"actual_arrival\",\n",
    "    \"arrival_gate\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(all_groundtruth_file):\n",
    "    os.remove(all_groundtruth_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing: ../../datasets/flights/flight_truth/2011-12-08-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2012-01-02-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-25-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-15-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-14-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-31-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-03-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2012-01-01-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-04-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-19-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-28-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-24-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-18-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-29-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-12-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-05-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-01-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-26-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-30-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-17-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-02-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-22-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-16-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-07-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-10-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-13-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-27-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2012-01-03-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-11-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-20-truth.txt\n",
      "Importing: ../../datasets/flights/flight_truth/2011-12-09-truth.txt\n"
     ]
    }
   ],
   "source": [
    "clean_truth = list()\n",
    "\n",
    "groundtruth_files = [f for f in os.listdir(groundtruth_folder) if not f.startswith('.')]\n",
    "\n",
    "for file_name in groundtruth_files:\n",
    "    \n",
    "    file_path = os.path.join(groundtruth_folder, file_name)\n",
    "\n",
    "    print(\"Importing: \" + file_path)\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"iso-8859-1\") as f:\n",
    "        \n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        year, month, day, c = file_name.split(\"-\")\n",
    "        dt_ex = DatetimeExtractor(int(year), int(month), int(day))\n",
    "\n",
    "        for i, row in enumerate(reader):\n",
    "            try:\n",
    "                flight = row[header_truth.index(\"flight_number\")].strip().upper()\n",
    "                departure_gate = import_gate(row[header_truth.index(\"departure_gate\")])\n",
    "                arrival_gate = import_gate(row[header_truth.index(\"arrival_gate\")])\n",
    "                scheduled_departure = dt_ex.get_datetime(row[header_truth.index(\"scheduled_departure\")])\n",
    "                scheduled_arrival = dt_ex.get_datetime(row[header_truth.index(\"scheduled_arrival\")])\n",
    "                actual_departure = dt_ex.get_datetime(row[header_truth.index(\"actual_departure\")])\n",
    "                actual_arrival = dt_ex.get_datetime(row[header_truth.index(\"actual_arrival\")])    \n",
    "            except Exception as p:\n",
    "                print(p)\n",
    "            \n",
    "            record = [flight, scheduled_departure, actual_departure, departure_gate, scheduled_arrival, actual_arrival, arrival_gate]\n",
    "            clean_truth.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_number</th>\n",
       "      <th>scheduled_departure</th>\n",
       "      <th>actual_departure</th>\n",
       "      <th>departure_gate</th>\n",
       "      <th>scheduled_arrival</th>\n",
       "      <th>actual_arrival</th>\n",
       "      <th>arrival_gate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA-1221-MCO-ORD</td>\n",
       "      <td>2011-12-08 20:00:00</td>\n",
       "      <td>2011-12-08 19:52:00</td>\n",
       "      <td>16</td>\n",
       "      <td>2011-12-08 21:50:00</td>\n",
       "      <td>2011-12-08 21:24:00</td>\n",
       "      <td>H11B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA-4307-ORD-DTW</td>\n",
       "      <td>2011-12-08 18:45:00</td>\n",
       "      <td>2011-12-08 18:37:00</td>\n",
       "      <td>H2</td>\n",
       "      <td>2011-12-08 21:10:00</td>\n",
       "      <td>2011-12-08 20:57:00</td>\n",
       "      <td>D28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA-616-DFW-DTW</td>\n",
       "      <td>2011-12-08 09:05:00</td>\n",
       "      <td>2011-12-08 09:00:00</td>\n",
       "      <td>C24</td>\n",
       "      <td>2011-12-08 12:35:00</td>\n",
       "      <td>2011-12-08 12:20:00</td>\n",
       "      <td>D32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA-431-MIA-SFO</td>\n",
       "      <td>2011-12-08 08:35:00</td>\n",
       "      <td>2011-12-08 08:31:00</td>\n",
       "      <td>D22</td>\n",
       "      <td>2011-12-08 11:50:00</td>\n",
       "      <td>2011-12-08 11:31:00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA-3756-ORD-SLC</td>\n",
       "      <td>2011-12-08 12:15:00</td>\n",
       "      <td>2011-12-08 12:12:00</td>\n",
       "      <td>H4</td>\n",
       "      <td>2011-12-08 14:45:00</td>\n",
       "      <td>2011-12-08 14:35:00</td>\n",
       "      <td>A3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     flight_number scheduled_departure    actual_departure departure_gate  \\\n",
       "0  AA-1221-MCO-ORD 2011-12-08 20:00:00 2011-12-08 19:52:00             16   \n",
       "1  AA-4307-ORD-DTW 2011-12-08 18:45:00 2011-12-08 18:37:00             H2   \n",
       "2   AA-616-DFW-DTW 2011-12-08 09:05:00 2011-12-08 09:00:00            C24   \n",
       "3   AA-431-MIA-SFO 2011-12-08 08:35:00 2011-12-08 08:31:00            D22   \n",
       "4  AA-3756-ORD-SLC 2011-12-08 12:15:00 2011-12-08 12:12:00             H4   \n",
       "\n",
       "    scheduled_arrival      actual_arrival arrival_gate  \n",
       "0 2011-12-08 21:50:00 2011-12-08 21:24:00         H11B  \n",
       "1 2011-12-08 21:10:00 2011-12-08 20:57:00          D28  \n",
       "2 2011-12-08 12:35:00 2011-12-08 12:20:00          D32  \n",
       "3 2011-12-08 11:50:00 2011-12-08 11:31:00           57  \n",
       "4 2011-12-08 14:45:00 2011-12-08 14:35:00           A3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groundtruth = pd.DataFrame(clean_truth)\n",
    "groundtruth.columns = header_truth\n",
    "groundtruth.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groundtruth.to_csv(all_groundtruth_file, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# groundtruth -> pandas dataframe with the groundtruth\n",
    "# claims -> pandas dataframe with all the claims\n",
    "# claims = pd.read_csv(all_claims_file)\n",
    "# groundtruth = pd.read_csv(all_groundtruth_file)\n",
    "\n",
    "#     Source    Object  Property   Value   Categorical\n",
    "# 0     A         o1      p1         b          1\n",
    "# 1     B         o1      p1         a          1\n",
    "# 2     C         o1      p1         a          1\n",
    "# 3     A         o2      p2         2          0\n",
    "# 4     B         o2      p2         1          0\n",
    "# 5     C         o2      p2         1          0\n",
    "# 6     A         o3      p3         a          1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_claims = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_trans_claims = [\"Source\", \"Object\", \"Property\", \"Value\", \"Categorical\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def get_datetime_minutes(date_to_convert):\n",
    "    if pd.isnull(date_to_convert):\n",
    "        date_to_convert = datetime(year=2012, month=12, day=1)\n",
    "    start_date = datetime(year=2011, month=12, day=1)\n",
    "    delta = date_to_convert - start_date\n",
    "    delta_minutes = round(delta.total_seconds() / 60, 3)\n",
    "    return delta_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claims to transform : 776067 \n",
      "10 % done...\n",
      "20 % done...\n",
      "30 % done...\n",
      "40 % done...\n",
      "50 % done...\n",
      "60 % done...\n",
      "70 % done...\n",
      "80 % done...\n",
      "90 % done...\n",
      "100 % done...\n"
     ]
    }
   ],
   "source": [
    "# header_claims = [\n",
    "#    \"source\",\n",
    "#    \"flight_number\",\n",
    "#    \"scheduled_departure\",\n",
    "#    \"actual_departure\",\n",
    "#    \"departure_gate\", \n",
    "#    \"scheduled_arrival\",\n",
    "#    \"actual_arrival\",\n",
    "#    \"arrival_gate\",\n",
    "# ]\n",
    "\n",
    "print(\"Claims to transform : %i \" %len(claims))\n",
    "\n",
    "for i, el in claims.iterrows():\n",
    "    \n",
    "    sd = [el[\"source\"], el[\"flight_number\"], \"scheduled_departure\", get_datetime_minutes(el[\"scheduled_departure\"]), 0]\n",
    "    ad = [el[\"source\"], el[\"flight_number\"], \"actual_departure\", get_datetime_minutes(el[\"actual_departure\"]), 0]\n",
    "    dg = [el[\"source\"], el[\"flight_number\"], \"departure_gate\", el[\"departure_gate\"], 1]\n",
    "    sa = [el[\"source\"], el[\"flight_number\"], \"scheduled_arrival\", get_datetime_minutes(el[\"scheduled_arrival\"]), 0]\n",
    "    aa = [el[\"source\"], el[\"flight_number\"], \"actual_arrival\", get_datetime_minutes(el[\"actual_arrival\"]), 0]\n",
    "    ag = [el[\"source\"], el[\"flight_number\"], \"arrival_gate\", el[\"arrival_gate\"], 1]\n",
    "    \n",
    "    transformed_claims.extend([sd, ad, dg, sa, aa, ag])\n",
    "    \n",
    "    if int( (i)/len(claims) * 100 ) < int( (i+1)/len(claims) * 100 ) and int( (i+1)/len(claims) * 100 ) % 10 == 0:\n",
    "        print(int( (i+1)/len(claims) * 100 ), \"% done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header_transformed_claims = [\"Source\", \"Object\", \"Property\", \"Value\", \"Categorical\"]\n",
    "pd_transformed_claims = pd.DataFrame(transformed_claims)\n",
    "pd_transformed_claims.columns = header_transformed_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Object</th>\n",
       "      <th>Property</th>\n",
       "      <th>Value</th>\n",
       "      <th>Categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UA</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>scheduled_departure</td>\n",
       "      <td>13805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UA</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>actual_departure</td>\n",
       "      <td>13980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UA</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>departure_gate</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UA</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>scheduled_arrival</td>\n",
       "      <td>13981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UA</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>actual_arrival</td>\n",
       "      <td>14144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UA</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>arrival_gate</td>\n",
       "      <td>E24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AIRTRAVELCENTER</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>scheduled_departure</td>\n",
       "      <td>527040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AIRTRAVELCENTER</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>actual_departure</td>\n",
       "      <td>13793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AIRTRAVELCENTER</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>departure_gate</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AIRTRAVELCENTER</td>\n",
       "      <td>UA-1534-RTB-IAH</td>\n",
       "      <td>scheduled_arrival</td>\n",
       "      <td>527040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Source           Object             Property   Value  Categorical\n",
       "0               UA  UA-1534-RTB-IAH  scheduled_departure   13805            0\n",
       "1               UA  UA-1534-RTB-IAH     actual_departure   13980            0\n",
       "2               UA  UA-1534-RTB-IAH       departure_gate       -            1\n",
       "3               UA  UA-1534-RTB-IAH    scheduled_arrival   13981            0\n",
       "4               UA  UA-1534-RTB-IAH       actual_arrival   14144            0\n",
       "5               UA  UA-1534-RTB-IAH         arrival_gate     E24            1\n",
       "6  AIRTRAVELCENTER  UA-1534-RTB-IAH  scheduled_departure  527040            0\n",
       "7  AIRTRAVELCENTER  UA-1534-RTB-IAH     actual_departure   13793            0\n",
       "8  AIRTRAVELCENTER  UA-1534-RTB-IAH       departure_gate       -            1\n",
       "9  AIRTRAVELCENTER  UA-1534-RTB-IAH    scheduled_arrival  527040            0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_transformed_claims.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth to transform : 2986 \n",
      "10 % done...\n",
      "20 % done...\n",
      "30 % done...\n",
      "40 % done...\n",
      "50 % done...\n",
      "60 % done...\n",
      "70 % done...\n",
      "80 % done...\n",
      "90 % done...\n",
      "100 % done...\n"
     ]
    }
   ],
   "source": [
    "# header_truth = [\n",
    "#    \"flight_number\",\n",
    "#    \"scheduled_departure\",\n",
    "#    \"actual_departure\",\n",
    "#    \"departure_gate\", \n",
    "#    \"scheduled_arrival\",\n",
    "#    \"actual_arrival\",\n",
    "#    \"arrival_gate\",\n",
    "# ]\n",
    "\n",
    "transformed_truth = list()\n",
    "header_transformed_truth = [\"Object\", \"Property\", \"Value\", \"Categorical\"]\n",
    "\n",
    "print(\"Truth to transform : %i \" %len(groundtruth))\n",
    "\n",
    "for i, el in groundtruth.iterrows():\n",
    "    \n",
    "    sd = [el[\"flight_number\"], \"scheduled_departure\", get_datetime_minutes(el[\"scheduled_departure\"]), 0]\n",
    "    ad = [el[\"flight_number\"], \"actual_departure\", get_datetime_minutes(el[\"actual_departure\"]), 0]\n",
    "    dg = [el[\"flight_number\"], \"departure_gate\", el[\"departure_gate\"], 1]\n",
    "    sa = [el[\"flight_number\"], \"scheduled_arrival\", get_datetime_minutes(el[\"scheduled_arrival\"]), 0]\n",
    "    aa = [el[\"flight_number\"], \"actual_arrival\", get_datetime_minutes(el[\"actual_arrival\"]), 0]\n",
    "    ag = [el[\"flight_number\"], \"arrival_gate\", el[\"arrival_gate\"], 1]\n",
    "    \n",
    "    transformed_truth.extend([sd, ad, dg, sa, aa, ag])\n",
    "    \n",
    "    if int( (i)/len(groundtruth) * 100 ) < int( (i+1)/len(groundtruth) * 100 ) and int( (i+1)/len(groundtruth) * 100 ) % 10 == 0:\n",
    "        print(int( (i+1)/len(groundtruth) * 100 ), \"% done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_transformed_truth = pd.DataFrame(transformed_truth)\n",
    "pd_transformed_truth.columns = header_transformed_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Object</th>\n",
       "      <th>Property</th>\n",
       "      <th>Value</th>\n",
       "      <th>Categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA-1221-MCO-ORD</td>\n",
       "      <td>scheduled_departure</td>\n",
       "      <td>11280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA-1221-MCO-ORD</td>\n",
       "      <td>actual_departure</td>\n",
       "      <td>11272</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA-1221-MCO-ORD</td>\n",
       "      <td>departure_gate</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA-1221-MCO-ORD</td>\n",
       "      <td>scheduled_arrival</td>\n",
       "      <td>11390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA-1221-MCO-ORD</td>\n",
       "      <td>actual_arrival</td>\n",
       "      <td>11364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AA-1221-MCO-ORD</td>\n",
       "      <td>arrival_gate</td>\n",
       "      <td>H11B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AA-4307-ORD-DTW</td>\n",
       "      <td>scheduled_departure</td>\n",
       "      <td>11205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AA-4307-ORD-DTW</td>\n",
       "      <td>actual_departure</td>\n",
       "      <td>11197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AA-4307-ORD-DTW</td>\n",
       "      <td>departure_gate</td>\n",
       "      <td>H2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AA-4307-ORD-DTW</td>\n",
       "      <td>scheduled_arrival</td>\n",
       "      <td>11350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Object             Property  Value  Categorical\n",
       "0  AA-1221-MCO-ORD  scheduled_departure  11280            0\n",
       "1  AA-1221-MCO-ORD     actual_departure  11272            0\n",
       "2  AA-1221-MCO-ORD       departure_gate     16            1\n",
       "3  AA-1221-MCO-ORD    scheduled_arrival  11390            0\n",
       "4  AA-1221-MCO-ORD       actual_arrival  11364            0\n",
       "5  AA-1221-MCO-ORD         arrival_gate   H11B            1\n",
       "6  AA-4307-ORD-DTW  scheduled_departure  11205            0\n",
       "7  AA-4307-ORD-DTW     actual_departure  11197            0\n",
       "8  AA-4307-ORD-DTW       departure_gate     H2            1\n",
       "9  AA-4307-ORD-DTW    scheduled_arrival  11350            0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_transformed_truth.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Claims:  4656402\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Claims: \", len(pd_transformed_claims))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ground Truth: \", len(pd_transformed_truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = \"flight_truth.csv\"\n",
    "\n",
    "if (os.path.exists(OUTPUT_FILE)):\n",
    "    os.remove(OUTPUT_FILE)\n",
    "    print(\"Removed: \" + OUTPUT_FILE)\n",
    "dataset = open(OUTPUT_FILE, \"w\")\n",
    "print(\"Created empty file: \" + OUTPUT_FILE)\n",
    "\n",
    "pd_transformed_truth.to_csv(OUTPUT_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = \"flight.csv\"\n",
    "\n",
    "if (os.path.exists(OUTPUT_FILE)):\n",
    "    os.remove(OUTPUT_FILE)\n",
    "    print(\"Removed: \" + OUTPUT_FILE)\n",
    "dataset = open(OUTPUT_FILE, \"w\")\n",
    "print(\"Created empty file: \" + OUTPUT_FILE)\n",
    "\n",
    "pd_transformed_claims.to_csv(OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import word2vec\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opeds_df = pd.read_csv('flight.csv', encoding='utf-8')\n",
    "pandas.set_option('mode.chained_assignment', None)\n",
    "datasetcsv = pandas.read_csv(\"flight.csv\")\n",
    "num_features = 60  # Word vector dimensionality\n",
    "min_word_count = 1 # Minimum word count\n",
    "num_workers = 4  # Number of threads to run in parallel\n",
    "context = 4  # Context window size\n",
    "downsampling = 1e-3  # Downsample setting for frequent words\n",
    "epoche = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_word2vec(x):\n",
    "  return modello[x]\n",
    "\n",
    "\n",
    "def vectorization(opeds_df):\n",
    "    count=0\n",
    "    lista1=[]\n",
    "    while(count<len(opeds_df)):\n",
    "        lista2=[]\n",
    "        lista2.append(opeds_df['Source'][count])\n",
    "        lista2.append(opeds_df['Object'][count])\n",
    "        lista2.append(opeds_df['Property'][count])\n",
    "        lista2.append(opeds_df['Value'][count])\n",
    "        lista1.append(lista2)\n",
    "        count+=1\n",
    "\n",
    "    model = word2vec.Word2Vec(lista1, workers=num_workers, size=num_features, min_count=min_word_count, window=context, sample=downsampling)\n",
    "    model.train(lista1, total_examples=len(lista1), epochs=epoche)\n",
    "\n",
    "    model_name = \"model\"\n",
    "    model.save(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorization(opeds_df)\n",
    "modello= gensim.models.Word2Vec.load('model')\n",
    "#datasetcsv_vec = pandas.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "print(\"iniziamo sorgenti\\n\")\n",
    "datasetcsv_vec['Source']   = datasetcsv['Source'].apply(to_word2vec)\n",
    "print(\"iniziamo object\\n\")\n",
    "datasetcsv_vec['Object']   = datasetcsv['Object'].apply(to_word2vec)\n",
    "print(\"iniziamo prperty\\n\")\n",
    "datasetcsv_vec['Property'] = datasetcsv['Property'].apply(to_word2vec)\n",
    "print(\"iniziamo value \\n\")\n",
    "datasetcsv_vec['Value']    = datasetcsv['Value'].apply(to_word2vec)\n",
    "\n",
    "print(datasetcsv_vec)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "entries = datasetcsv.groupby(['Object', 'Property'])\n",
    "\n",
    "# NOTA: per tutte le coppie (Object, Property) devono esprimersi tutt\n",
    "# fonti\n",
    "source_number  = len(datasetcsv['Source'].unique())\n",
    "entries_number = len(entries)\n",
    "x_size = 3 * num_features\n",
    "\n",
    "dataset_continues = np.zeros((entries_number, source_number), dtype=np.float32)\n",
    "dataset_is_categorical = np.zeros((entries_number), dtype=np.bool)  # is the n-th I categorical? True/False\n",
    "dataset_I = np.zeros((entries_number, source_number, x_size), dtype=np.float32)  # I\n",
    "\n",
    "\n",
    "conteggio=0\n",
    "conteggo2=0\n",
    "for i, entry_key in enumerate(entries.groups):\n",
    "    print(entry_key)\n",
    "\n",
    "    entry = entries.get_group(entry_key)\n",
    "\n",
    "    entry['Object'] = entry['Object'].apply(to_word2vec)\n",
    "    entry['Property'] = entry['Property'].apply(to_word2vec)\n",
    "\n",
    "    # is categorical\n",
    "    dataset_is_categorical[i] = np.bool(entry.iloc[0]['Categorical'] == 1)\n",
    "\n",
    "    obj, prop = entry.iloc[0]['Object'], entry.iloc[0]['Property']\n",
    "    conteggio+=1\n",
    "   # print(conteggio)\n",
    "    conteggo2=0\n",
    "    for s in range(source_number):\n",
    "        conteggo2+=1\n",
    "        #print(conteggo2)\n",
    "        # cont values\n",
    "        if not dataset_is_categorical[i]:\n",
    "            try:\n",
    "                dataset_continues[i, s] = entry.iloc[s]['Value']\n",
    "                print(entry.iloc[s]['Value'])\n",
    "                val = entry.iloc[s]['Value']\n",
    "                lastvalid=entry.iloc[s]['Value']\n",
    "            except IndexError as e:\n",
    "                dataset_continues[i, s] = lastvalid\n",
    "                val = lastvalid\n",
    "\n",
    "        # I\n",
    "        else:\n",
    "            try:\n",
    "                print(entry.iloc[s]['Value'])\n",
    "                val = entry.iloc[s]['Value']\n",
    "            except:\n",
    "                val = '-'\n",
    "        val = to_word2vec(val)\n",
    "\n",
    "        dataset_I[i, s] = np.concatenate([obj, prop, val])\n",
    "    #print(dataset_I)\n",
    "\n",
    "'''\n",
    "print(\"I\" + \"\\n\")\n",
    "print(dataset_I)\n",
    "print(\"CATEGORICAL\" + \"\\n\")\n",
    "print(dataset_is_categorical)\n",
    "print(\"CONT_VALUES\", \"\\n\", dataset_continues)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d_cate(truth_value, value):\n",
    "    print(\"sono in d_cate\")\n",
    "    equals_elementwise = tf.equal(truth_value, value)\n",
    "    equals = tf.reduce_all(equals_elementwise)\n",
    "    return 1 - tf.cast(equals, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# distanza continua fra truth_value e value\n",
    "def d_con(truth_value, value, values):\n",
    "    print(\"sono in d_cone\")\n",
    "    abs_diff = tf.abs(truth_value - value)\n",
    "\n",
    "    mean = tf.reduce_mean(values)\n",
    "    den = tf.sqrt(tf.reduce_sum((values - mean) ** 2))\n",
    "\n",
    "    # if den == 0 and abs_diff == 0, then we have 0/0\n",
    "    # and tensorflow returns nan. We know that 0/0 means\n",
    "    # that the distance is 0\n",
    "    d_zero = tf.logical_and(tf.equal(abs_diff, 0.0), tf.equal(den, 0.0))\n",
    "\n",
    "    d = tf.cond(d_zero, lambda: tf.constant(0.0), lambda: abs_diff / den)\n",
    "    return d\n",
    "\n",
    "\n",
    "def get_majority(values):\n",
    "    values_tensor = tf.stack(values)\n",
    "    counts = []\n",
    "\n",
    "    for value in values:\n",
    "        one_if_equal = lambda v: tf.cast(tf.equal(value, v), dtype=tf.float32)\n",
    "        one_where_equal = tf.map_fn(one_if_equal, values_tensor)\n",
    "        count = tf.reduce_sum(one_where_equal)\n",
    "\n",
    "        counts.append(count)\n",
    "    #va aggiunto controllo che il carattere deve essere diverso da \"-\"\n",
    "    index_max = tf.argmax(tf.stack(counts))\n",
    "\n",
    "    return values_tensor[index_max]\n",
    "\n",
    "\n",
    "def weighted_median(values, weights):\n",
    "    # We have to find Wi in W satisfy:\n",
    "    #     - the sum of the elements on its  left are <  sum(weight)/2\n",
    "    #     - the sum of the elements on its right are <= sum(weight)/2\n",
    "    # then return values[i], working with a sorted weights based on values\n",
    "\n",
    "    half = tf.reduce_sum(weights) / 2.0\n",
    "\n",
    "    sorted_values, sorted_index = tf.nn.top_k(values, values.shape[-1], sorted=False)\n",
    "    sorted_weights = tf.gather(weights, sorted_index)\n",
    "\n",
    "    satisfy_at_index = []\n",
    "\n",
    "    for i in range(values.shape[-1]):\n",
    "        left_sum = tf.reduce_sum(sorted_weights[0:i])\n",
    "        right_sum = tf.reduce_sum(sorted_weights[i + 1:])\n",
    "\n",
    "        satisfy = tf.logical_and(tf.less(left_sum, half),\n",
    "                                 tf.less_equal(right_sum, half))\n",
    "\n",
    "        satisfy_at_index.append(tf.cast(satisfy, dtype=tf.int32))\n",
    "\n",
    "    where_satisfy = tf.argmax(satisfy_at_index)\n",
    "\n",
    "    return sorted_values[where_satisfy]\n",
    "\n",
    "\n",
    "def loss_cate(R, I):\n",
    "    print(\"sono in loss_cate\")\n",
    "    xes = tf.unstack(I)\n",
    "\n",
    "    values = []\n",
    "    for x in xes:\n",
    "        obj, property, value = tf.split(x, 3)\n",
    "        values.append(value)\n",
    "\n",
    "    # the truth is is the majority\n",
    "    truth_value = get_majority(values)\n",
    "\n",
    "    l = 0.0\n",
    "    for s, value in enumerate(values):\n",
    "        l += R[s] * d_cate(truth_value, value)\n",
    "\n",
    "    return l\n",
    "\n",
    "\n",
    "def loss_cont(R, cont_values):\n",
    "    print(\"sono in loss_cont\")\n",
    "    truth_value = weighted_median(cont_values, R)\n",
    "\n",
    "    l = 0.0\n",
    "\n",
    "    values = tf.unstack(cont_values)\n",
    "    for s, value in enumerate(values):\n",
    "        l += R[s] * d_con(truth_value, value, cont_values)\n",
    "\n",
    "    return l\n",
    "\n",
    "\n",
    "def loss(i_batch, R, continues_placeholder, is_categorical_batch):\n",
    "    print(\"sono in loss\")\n",
    "    l = 0.0\n",
    "    count=0\n",
    "    for i, is_categorical in enumerate(tf.unstack(is_categorical_batch, axis=0)):\n",
    "        print(i)\n",
    "        if count>10:\n",
    "            return l*40000\n",
    "        else:\n",
    "            print(count)\n",
    "        count+=1\n",
    "        \n",
    "        l += tf.cond(is_categorical,\n",
    "                     lambda: loss_cate(R[i], i_batch[i]),\n",
    "                     lambda: loss_cont(R[i], continues_batch[i]))\n",
    "    return l\n",
    "\n",
    "\n",
    "def FFMN(K, statement_size):\n",
    "  with tf.variable_scope(\"FFMN\", reuse=tf.AUTO_REUSE):\n",
    "    I = tf.placeholder(tf.float32, shape=(None,\n",
    "                                        k,\n",
    "                                        statement_size))\n",
    "\n",
    "    M = tf.get_variable(\"M\", [k, statement_size], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=1.0))\n",
    "    O = tf.reduce_sum(tf.multiply(I, M), axis=2)\n",
    "    R = tf.nn.softmax(O, axis=1)\n",
    "  return I, R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = source_number\n",
    "\n",
    "batch_size = entries_number\n",
    "continues_batch = tf.placeholder(tf.float32, shape=(batch_size, k))\n",
    "is_categorical_batch = tf.placeholder(tf.bool, shape=(batch_size))\n",
    "\n",
    "input_batch, R = FFMN(k, 3*num_features)\n",
    "print(\"prima di loss\")\n",
    "l = loss(input_batch, R, continues_batch, is_categorical_batch)\n",
    "print(l)\n",
    "ADA = tf.train.AdamOptimizer()\n",
    "print(ADA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"opt\", reuse=tf.AUTO_REUSE):\n",
    "  minimization_op = ADA.minimize(l)\n",
    "\n",
    "print(\"aggio fatto \")\n",
    "with tf.Session() as s:\n",
    "  s.run(tf.global_variables_initializer())\n",
    "\n",
    "  for i in range(1000):\n",
    "      print(i)  \n",
    "      _, lo = s.run([minimization_op, l], feed_dict={\n",
    "          input_batch: dataset_I,\n",
    "          continues_batch: dataset_continues,\n",
    "          is_categorical_batch: dataset_is_categorical\n",
    "      })\n",
    "    \n",
    "\n",
    "      if i % 100 == 0:\n",
    "          print(lo)\n",
    "\n",
    "  print(\"\")\n",
    "\n",
    "  np.set_printoptions(suppress=True)\n",
    "\n",
    "  print(s.run([R], feed_dict={\n",
    "      input_batch: dataset_I\n",
    "  }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
